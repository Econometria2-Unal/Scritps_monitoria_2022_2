##____________________________________________________________________________________
##____________________________________________________________________________________
#       UNIVERSIDAD NACIONAL DE COLOMBIA - FACULTAD DE CIENCIAS ECON?MICAS
#                         ECONOMETRIA II - 2022-I
#           Monitoria: Cointegración - Metodología Engle & Granger.
##____________________________________________________________________________________
##_____________________________________________________________________________________

## Limpiar el entorno de objetos
remove(list = ls())

# Se importan algunos paquetes que van a utilizar a lo largo de la metodología 

# Paquetes de proposito general 
library(tidyverse) # Conjunto de paquetes fundamental para manejo de datos enR
library(broom) # Paquete para analizar modelos en R
library(readxl) # Para importar archivos excel en R

# Paquetes de series de tiempo 

library(dynlm) # Paquete para realizar MCOD (DOLS) y modelos de corrección de error en R
library(urca) # Paquete para realizar pruebas de raíz unitaria y cointegración en R
library(car) # Para usar la función qqPlot
library(aTSA)
library(forecast)
library(tseries)
library(rlang)

# Notas sobre cointegración: 

# En economía, nos interesa poder analizar las relaciones económicas entre diferentes
# variables económicas, y en particular, en macroeconomía nos interesa estudiar
# las relaciones que se pueden establecer entre variables agregadas. 

# La metodología de cointegración, nos permite analizar relaciones de largo plazo
# entre dos o más variables analizando la tendencia o comportamiento común entre éstas, 
# y en metadologías más generales como lo son la metodología de Johansen
# se pueden estudiar dos o más relaciones de cointegración entre varias variables. 

# La cointegración entre dos o más variables, implica la existencia de una tendencia 
# estocástico común entre dichas variables, lo que hace que éstas tiendan a tener un 
# movimiento común a largo plazo alrededor de un "atractor" o punto de equilibro que
# determina de algún modo el movimiento común de la variables alrededor de éste. 

# Existen varias metodologías de cointegración en la literatura: 
## ARDL
## Metodología de Engle-Granger 
## Metodología de Johansen

# En el curso se estudiaran la metodología de Engle-Granger (que es el procedimiento
# que veremos en el presente Script) y metodología de Johansen (que lo veremos luego 
# de ver la metodología de VAR)

# La metodología de cointegración ha tenido una fuerte acogida en la literatura de 
# macroeconomía, en particular, los académicos y bancos centrales la han empleado 
# para estudiar de manera exitosa las relaciones entre variables cambiarias y monetarias
# con el fin de formular teoría económica y orientar mejor el diseño de política pública. 

# Ejemplos de cointegración en la literatura: 
## Hipótesis del ingreso permanente de Friedman
## Ley de precio único
## Unbiased forward rate hypothesis (Insesgadez en la tasa forward como predictor de la tasa spot futura de una moneda)
## Movimiento conjunto de una casta de divisas (e.g. de las principales divisas, de las monedas de AL, demás)
## Hipótesis de expectativas de la estructura temporal de la tasa de interés (ejemplo 1 del script)
## Paridad de poder adquisitivo (PPP) y arbitraje en el mercado de bienes (ejemplo 2 del script)

# Revisar el capítulo 6.1 del Enders para profundizar sobre algunos ejemplos de
# cointegración entre variables que se puede encontrar en la literatura

# 1. Expectations hypothesis: Hipótesis de expectativas de la estructura temporal de la tasa de interés  ----

# En economía financiera, existe la concepción de que las tasas de interés de corto
# y de largo plazo de los bonos de un mismo país tienden a tener un movimiento común.
# Bono, entendido como ese instrumento/vehículo de financiación que utilizan los países
# para conseguir financiación extranjera
# El análisis se centra en la explicación de la famosos Yield Curve de dichos bonos
# y en explicar su dinámica así como su pendiente 
# Existen diferentes teorías que intentan explicar este comportamiento común de las 
# tasa de interés de dichos bonos. 

# Modelos de tasas de interés: 
### 1. La teoría de expectativas en la estructura temporal: 
###    Teoría más famosa y más comúnmente empleada pero de la que se sabe que tiene 
###    complicaciones o está incompleta)
### 2. Liquidity preference hypothesis: La teoría por la preferencia por la liquidez
###     argumenta que los inversionistas exigen una "prima" adicional de retorno 
###     para invertir en bonos de LP dado que los consideran más riesgosos que los bonos
###     de corto plazo
### 3. Modelos dinámicos: Vasicek, Cox-Ingersoll-Ross

# En general, se espera que las tasas de largo plazo sean mayores a las tasas de corto 
# plazo y por ende una pendiente positiva de la famosa Yield Curve. Cuando la Yield
# Curve se invierte, entonces las tasas de CP son mayores a las tasas de LP. Cuando lo
# anterior ocurre, los inversionistas y agentes del mercado suelen asociar a dicha
# inversión en la Yiled Curve como un presagio de que algo va a ocurrir en la economía
# algunas personas inclusive asocian a dicha inversión de la Yield Curve como una 
# señal de que una economía va a entrar en recesión (aunque este "hecho estilizado" no 
# siempre se cumple o se observa en la realidad)

# El presente es un ejemplo del libro Introduction to econometrics with R de Hanck, Arnold, Gerber y Schmelzer. 
# Disponible en el siguiente link: https://www.econometrics-with-r.org/16-3-cointegration.html

# Nota: https://www.econometrics-with-r.org/ es un libro online bastante interesante, en la medida que tiene los códigos en R
#       adaptados a los ejemplos del libro Introduction to Econometrics by Stock and Watson (2015) por lo que van a poder 
#       encontrar material de muy buena calidad en diversos temas de econometría en general, por lo que se les recomienda bastante 
#       que revisen los temas del libro porque podrían encontrar códigos de su interés. 

# Para este ejemplo veremos la relacion entre la tasa de interés 
# de corto plazo (Treasury bills a 3 meses) y la tasa de interés de largo plazo (Treasury
# bonds a 10 años) de los Estados Unidos. En caso de estar cointegradas las series, 
# se esperaría que el spread entre estas dos tasas, que es básicamente la diferencia
# entre las dos tasas, sea una serie estacionaria. 
# En algunos contextos, se utiliza la Treasury bills a 3 meses como la tasa libre de 
# riesgo mientras que en otros se emplea la Treasury bonds a 10 años como la tasa libre de
# riesgo

# Importación de la base de datos 

# La base de datos USMacroSWQ contiene diferentes series de tiempo relacionadas con 
# variables macroeconómicas de interés de los Estados Unidos. En particular, contiene
# la serie histórica de las tasas de interés de los bonos del Tesoro de los EE.UU.
# A 3 meses (TB3MS), a un año (GS1) y a 10 años (GS10)
USMacroSWQ <- read_xlsx(file.choose(),sheet = 1,col_types = c("text", rep("numeric", 9)))

# Formato de la columna fecha (date)
USMacroSWQ$...1 <- as.yearqtr(USMacroSWQ$...1, format = "%Y:0%q")

# Ajustamos nombres de las columnas
colnames(USMacroSWQ) <- c("Date", "GDPC96", "JAPAN_IP", "PCECTPI",
                          "GS10", "GS1", "TB3MS", "UNRATE", "EXUSUK", "CPIAUCSL")

# Visualización de la base de datos
glimpse(USMacroSWQ)

# Tasa de interés 3-months Treasury bills
TB3MS = ts(USMacroSWQ$TB3MS, start = c(1957,1), end = c(2013,4), frequency = 4)
# Tasa de interés 10-years Treasury bonds
TB10YS = ts(USMacroSWQ$GS10,start = c(1957,1), end = c(2013,4), frequency = 4)


# Se analiza el comportamiento gráfico de las dos tasas
x11()
plot(merge(as.zoo(TB3MS), as.zoo(TB10YS)),
     plot.type = "single",
     lty = c(2, 1),
     lwd = 2,
     xlab = "Año",
     ylab = "Porcentaje anual",
     ylim = c(-5, 17),
     main = "Tasas de interés")

# Ahora se grafica el spread de las dos tasas en la misma gráfica.
lines(as.zoo(TB10YS-TB3MS),
      col = "steelblue",
      lwd = 2,
      xlab = "Año",
      ylab = "Porcentaje anual")

# Se añade la leyenda
legend("topright",
       legend = c("TB3MS", "TB10YS", "Spread"),
       col = c("black", "black", "steelblue"),
       lwd = c(2, 2, 2),
       lty = c(2, 1, 1))

# Del anterior gráfico es posible concluir que las series posiblemente están cointegradas, en tanto:
# las series en nivel aparentemente son I(1) (aparentan tener una tendencia estocástica común), y finalmente, 
# el spread entre ellas parece ser estacionario (la combinación lineal entre ambas parece eliminar la tendencia estocástica)

# A nivel económico la anterior gráfica da bastante información relevante. Observar el
# comportamiento de las tasas de interés de los Estados Unidos dice bastante sobre la
# política monetaria que condujó la FED y el estado la economía norteaméricana. Por ejemplo,
# Se puede observar como en los 80s Volcker aumentó fuertemente las tasas de interés 
# de EE.UU. para combatir la inflación, lo que tuvó fuertes consecuencias en crecimiento 
# y pagos de la deuda en los países de América Latina. También, muestra las bajas tasas
# de interés de la FED luego de la crisis sub-prime del 2008

###
# Metodología Engle & Granger para la hipótesis de expectativas: 
###

# Paso 1: Uso de la prueba ADF y KPSS sobre las series ----

# 1.1 ADF y KPSS sobre la tasa de interés de los T-Bills a 3 meses ----

# Primero vamos a hacer una prueba de ADF con tendencia e intercepto. Los valores críticos de la prueba son sensibles a 
# la inclusión de términos determinísticos, de manera que hay que determinar si la serie tiene tendencia y/o intercepto. 

# El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi3 me dice si la tendecia es 
# significativa o no, y por tanto, si el el test de raíz unitaria debería incluir o no tendencia. 
adf1 = ur.df(TB3MS, lags=4, type = "trend"); plot(adf1)
summary(adf1)

# El tau nos dice que la serie tiene al menos una raíz unitaria, mientras el phi3 nos dice que la tendencia 
# no es significativa. Por lo tanto, vamos a mirar únicamente la prueba con intercepto.

#El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi1 me indica si la deriva es
#significativa, y por consiguiente, si se debe incluir en el test de raíz unitaria. 
adf2 = ur.df(TB3MS, lags=4, type = "drift"); plot(adf2)
summary(adf2)

#Los resultados indican que la serie tiene al menos una raíz unirtaria. El phi1, por su parte, indica que 
#la deriva de la serie no es significativa, por tanto, debe hacerse una prueba sin deriva

#Esta es la correcta especificación de la prueba dado que los términos determinísticos no son significativos. 
adf3 = ur.df(TB3MS,lags=4, type = "none"); plot(adf3)
summary(adf3)

#Claramente se evidencia que la serie tiene al menos una raíz unitaria, en tanto no se rechaza la hipótesis nula. 
#Noten la importancia de determinar si la serie tiene términos detemrminísticos, pues el valor calculado en cada
#especificación de la prueba cambió de forma importante.

# Hay dos tipos de pruebas importantes que se emplea comúnente en la literatura para 
# inverstigar si una serie tiene o no tiene raíz unitaria: 
## 1. La familia de las pruebas tipo ADF donde la hipótesis nula es no estacionariedad
## 2. La familia de pruebas donde la hipótesis nula es estacionariedad. La más famosas de este tipo de prueba
##    es la prueba KPSS

# Nota: En la práctica es muy usual emplear al menos estas dos tipos de prueba para verificar la estacionariedad
#       de una serie, de tal forma que se puedea obtener una diagnóstico más profundo del comportamiento de la serie
#       y de si presenta o no una tendencia estocástica la serie de tiempo.

# Hacemos la prueba KPSS cuya hipótesis nula es que la serie es estacionaria, la cual es totalmente contraria a la ADF. 
# Se toman 4 rezagos porque fueron los mismos utilizados en las pruebas ADF
kp1 = ur.kpss(TB3MS, use.lag = 4, type = "mu") #el mu nos indica que es una prueba sin términos determinísticos.
summary(kp1)

# Claramente rechazamos la hipótesis nula de estacionariedad, así que la serie de la tasa
# de interés de los treasury bills a 3 meses no es estacionaria. 

# 1.1 ADF y KPSS sobre la tasa de interés de los T-Bonds a 10 años ----

# Primero vamos a hacer una prueba de ADF con tendencia e intercepto. Los valores críticos de la prueba son sensibles a 
# la inclusión de términos determinísticos, de manera que hay que determinar si la serie tiene tendencia y/o intercepto. 

# El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi3 me dice si la tendecia es 
# significativa o no, y por tanto, si el el test de raíz unitaria debería incluir o no tendencia. 
adf4 = ur.df(TB10YS,lags=1, type = "trend"); plot(adf4)
summary(adf4)

# El tau nos dice que la serie tiene al menos una raíz unitaria, mientras el phi3 nos dice que la tendencia 
# no es significativa. Por lo tanto, vamos a mirar únicamente la prueba con intercepto.

# El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi1 me indica si la deriva es
# significativa, y por consiguiente, si se debe incluir en el test de raíz unitaria. 
adf5 = ur.df(TB10YS, lags=1, type = "drift"); plot(adf5)
summary(adf5)

# Los resultados indican que la serie tiene al menos una raíz unitaria. El phi2, por su parte, indica que 
# la deriva de la serie no es significativa, por tanto, debe hacerse una prueba sin deriva

#Esta es la correcta especificación de la prueba dado que los términos determinísticos no son significativos. 
adf6 =  ur.df(TB10YS, type = "none"); plot(adf6)
summary(adf6)

# Claramente se evidencia que la serie tiene al menos una raíz unitaria, en tanto no se rechaza la hipótesis nula. 
# Noten la importancia de determinar si la serie tiene términos detemrminísticos, pues el valor calculado en cada
# especificación de la prueba cambió de forma importante.

#Hacemos la prueba KPSS cuya hipótesis nula es que la serie es estacionaria, la cual es totalmente contraria a la ADF. 
kp2 = ur.kpss(TB10YS, use.lag = 1, type = "mu") #el mu nos indica que es una prueba sin términos determinísticos.
summary(kp2)
plot(kp2)

# Claramente rechazamos la hipótesis nula de estacionariedad, así que las serie tiene al menos una raíz unitaria. 


#Hacemos la prueba ADF sobre las series diferenciadas para confirmar que son I(1)
adf8 = ur.df(diff(TB3MS), lag=2, type = "none");plot(adf8); summary(adf8) #Estacionaria. 
adf7 = ur.df(diff(TB10YS), lag=1, type = "none");plot(adf7); summary(adf7) #Estacionaria

# Paso 2: Estimación de los residuales de la regresión en niveles ----

# La teoría económica (teoría de expectativas de la estructura temporal de las tasas de interés) 
# sugiere que el vector de cointegración es -1. Para corroborar lo anterior empíricamente, 
# se empieza encontrando el valor del vector de cointegración. 

# El comando dynlm: Me permite estimar estimar modelos lineales dinámicos
#                   Incluyendo modelos dinámicos de series de tiempo. 
#                   Modelos que permite estimar: MCO, MCO Dinámicos (DOLS), 
#                   modelos de corrección de error. 
#                   Funciona tanto con objetos ts como con objetos zoo
#                   

# Nota: 
## TB3MS: Tasa de interés de los T-bills de EE.UU. a 10 años 
## TB10YS: Tasa de interés de los Treasury bones de los EE.UU. a 10 años 

# 2.1 Estimación por MCO: ----

# Test de cointegración de Engle-Granger: 
# Pasos: 
## 1. Estimar por MCO o por MCOD (DOLS) el parámetro de cointegración 
##    entre las dos series que se creen que están cointegradas
## 2. Recuperar los residuales de la regresión anterior
## 3. Efectuar un test ADF sobre dichos residuales para saber si son o no son 
##    estacionarios. En caso de ser estacionarios, según el test de engle-granger
##    las series están cointegradas y en caso de no ser estacionarios, entonces
##    según este mismo test las series no están cointegradas.
## 4. Emplear los valores críticos modificados para el test de cointegración de 
##    Engle-Granger (e.g. ver la Tabla C. del manual suplementario del Enders). 
##    Si bien, los valores críticos cambian, la mecáncia del test de Engle-Granger
##    para cointegración es la misma que se haría para una serie solo se que se 
##    aplica a los residuales de una regresión y se deben ajustar los valores críticos
##    para el análisis

# Si TB3MS y TB10YS son series I(1) y además están cointegradas, se puede estimar una regresión en niveles:  
# El estimador de MCO de la regresión en niveles es consistente cuando yt y zt están cointegradas
FS_EGADF <- dynlm(TB10YS ~ TB3MS) 
summary(FS_EGADF)

# También es posible encontrar los resultados de la regresión utilizando
# el comando tidy() del paquete broom
tidy_FS_EGADF = tidy(FS_EGADF)

# Parámetro/vector de cointegración calculado por MCO: 
coint_param_MCO = tidy_FS_EGADF$estimate[2]; coint_param_MCO

# Se obtienen los residuales de la regresión
z_hat <- residuals(FS_EGADF)

# La idea, es verificar si los residuales de la regresión son estacionarios, 
# es decir, si son I(0), porque de serlo se sabe que la serie de residuales 
# seria estacionaria y por tanto las series estarian cointegradas

# Graficamos los residuales y analizamos su ACF y PACF
x11()
plot.ts(z_hat)

lags = 18
par(mfrow=c(1,2))
acf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='ACF de los residuales') 
pacf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='PACF de los residuales')

# Hacemos la prueba ADF sin términos determinísticos.
adf9 = ur.df(z_hat,lags=1,type = "none"); plot(adf9); summary(adf9) #Los rsiduales son estacionarios: hay cointegración. 

# No obstante, la prueba de ur.df ofrece valores críticos que no corresponden a los valores que se requieren para la prueba de cointegración 
# a pesar de que las mecánica sea lo misma (Estimo por MCO la regresión entre TB10YS ~ TB3MS, cálculo los resdiduales de dicha regresión y 
# realizo una prueba de ADF pero utilizando los valores críticos correctos (test de Engle-Granger))

# Lo anterior, se debe a que los residuales fueron estimados (no son las verdaderas innovaciones porque no 
# son conocidas) debido a que  el vector de cointegración (el theta) en el caso univariado tuvo que ser estimado en la primer etapa

# A la hora de calcular los valores criticos para la prueba de Engle-Granger hay que tener en cuenta tanto el numero de observaciones como 
# variables que se encuentren en la relacion de cointegracion (número de variables cointegradas)
# Para mas info ver enders 6.4 y el suppelementary manual 
# En el manual suplementario del Enders, 
# en TABLE C: Critical Values for the Engle − Granger Cointegration Test
# se encuentran los valores críticos para efectuar un test de cointegración de Engle-Granger

# También es posible ejecutar la prueba de cointegración de engle-granger de manera automática de una vez
# El comando coint.test del paquete aTSA permite realizar los dos pasos de la prueba de cointegración 
coint.test(TB10YS, TB3MS)

# type: el comando da tres resultados diferentes (para este ejemplo se usara el valor de type1)
## type1 es para prueba sin tendencia determinística 
## type2 es para prueba con tendencia lineal
## type3 es para prueba con tendencia cuadrática
# nlag: número de rezagos para la prueba de ADF (utilizamos los mismos que seleccionó el AIC)
# Generalmente el comando escoge automáticamente el numero de rezagos a usar 

# El test Type1: no trend, muestra que se rechaza la hipótesis nula 
# de no cointegración a favor de la hipótesis alternativa de que las series 
# están cointegradas (que es equivalente a que los residuales de la primera
# etapa o primera regresión son estacionarios)

# Nota: A veces el test de cointegración de engle-granger puede no dar cointegración en una dirección de las variables,
#       es decir en x ~ y, pero en la otra dirección sí puede dar cointegración y ~ x, o viceversa. Por tanto, es importante
#       que estimen ambas relaciones y miren si en alguno da que las series están cointegradas, basta con que una de ellas
#       muestre cointegración. Una de las devesventajas de la metodología de Engle-Granger es que no es claro el orden
#       de las variables en la relación y es necesario establecer un "orden" (además de solo poder establecer una relación 
#       de cointegración a la vez). La metodología de Johansen (que veremos más adelante) es más general en la medida
#       de que: 1) no necesita ningún "orden" en las variables para analizar su vector de cointegración y 2) me estima varias
#       reaciones de cointegración entre más de dos variables (en casi de existir dichas relaciones)

# numero de datos a la hora de realizar el test de cointegracion 
length(TB10YS)

# Si se usa la tabla c del supplementary manual del Enders se encuentra que cuando se tiene alrededor 
# De 200 datos Y 2 variables en la relación de cointegración, el test rechaza la hipotesis nula 
# de no cointegracion a valores de significancia del  5% pero no del 1%. Como en economia se usa generalmente un 
# nivel de significancia del 5 % se concluye de que hay cointegracion entre TB10YS y TB3MS

# Paso 3: Regresión con variables cointegradas ----

# 3.1 Modelo de Minimos Cuadrados Ordinarios Dinámicos ----

# Ahora bien, en la práctica es mucho más usual realizar un modelo de Mínimos cuadrados dinámicos (MCOD) o
# DOLS (Dynamic Ordinary Least Squares), dado que a pesar de que cuando las series están cointegradas MCO 
# es una metodología consistente, se tiene que MCO tiene una distribución no normal por lo que la 
# inferencia estadística no es válida. 

# Se prefiere emplear MCOD sobre MCO para cálcular el parámetro de cointegración, por dos razones: 
## 1. Inferencia estadísticas válida acerca de dicho parámetro puede realizarse incluyendo valores pasados, 
## presentes y futuros de delta y_t y usando erroes estándar robustos HAC
## 2. Al permitir incluir valores pasados, presentes y futuros, da mayor flexibilidad a la estimación y por
## tanto una mayor precisión en la estimación del parámetro de cointegración 

# Asumiremos que hay un máximo de 6 rezagos, por lo tanto, miraremos cuál tiene el menor AIC.
# La selección del modelo DOLS a emplear, también se basa en el que minimice el criterio AIC
# (tal como se hacía cuando se seleccionaban modelos ARIMA usando criterios de información)
# d(x, k) significa diferencia, donde k implica el orden de la diferencia (por default k = 1)
# es decir d(x, k) es equivalente a diff(x, lag = k) dentro del comando dynlm
# L significa rezagos. Así L(d(TB3MS),-1:1)) significa incluya los adelantes y rezagos
# de la primera diferencia de TB3MS. -1 esta asociado con el adelanto mientras que 1 con el rezago
# Ojo con los signos! -1 denota un adelanto en la serie (un paso adelante) y 1 denota un rezago 
# (un paso atrás tal y como se ve rezagos/lags en clase)

# Tener en cuenta que para un modelo dinámico es necesario incluir tanto rezagos como adelantos
# Para que la inferencia sea válida 

FS_MCOD1 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-1:1)); summary(FS_MCOD1)
FS_MCOD2 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-2:2)); summary(FS_MCOD2)
FS_MCOD3 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-3:3)); summary(FS_MCOD3)
FS_MCOD4 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-4:4)); summary(FS_MCOD4)
FS_MCOD5 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-5:5)); summary(FS_MCOD5)
FS_MCOD6 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-6:6)); summary(FS_MCOD6)


# Se selecciona el modelo que minimice el AIC
cbind(AIC(FS_MCOD1), AIC(FS_MCOD2), AIC(FS_MCOD3), AIC(FS_MCOD4), AIC(FS_MCOD5), AIC(FS_MCOD6))

# Se elige el modelo con 6 rezagos y 6 adelantos, en tanto tuvo el menor AIC
summary(FS_MCOD6)

# También es posible encontrar los resultados de la regresión utilizando
# el comando tidy() del paquete broom
tidy_FS_MCOD6 = tidy(FS_MCOD6)

# Parámetro/vector de cointegración calculado por MCO: 
coint_param_MCOD = tidy_FS_MCOD6$estimate[2]; coint_param_MCOD

# Observen que ahora la estimación del vector/parámetro de cointegración 
# dió 0.95737 lo cuál es bastante cercano al valor teórico de 1 que es espera
# por la teoría de expectativas de tasa de interés en la estructura temporal
# de tasas de interés. De igual forma, se observa que a pesar de que da significativo
# el coeficiente, hay que realizar la prueba de significancia individual con errores
# robustos tipo HAC para corroborar que en efecto el parámetro sea significativo

# Se calculan los residuales del modelo FS_MCOD6: 
residuals_FS_MCOD6 = residuals(FS_MCOD6)

# Graficamos el spread que dice la teoría económica resepcto al 
# spread "empírico" que obtuvimos:
### TB10YS-TB3MS: Es un spread teórico, en la medida de que asume un vector
###               de cointegración de 1
### residuals_FS_MCOD6: Es el "spread" que se observaría si se asumiera el vector
###                      de cointegración igual a 0.95737

x11()
plot(merge(as.zoo(TB10YS-TB3MS), as.zoo(residuals_FS_MCOD6)),
     plot.type = "single",
     lty = c(2, 1),
     lwd = 2,
     ylim = c(-5, 5),
     xlab = "Año",
     ylab = " ",
     main = "Diferencias")

legend("bottomright",
       legend = c("Spread","MCOD"),
       col = c(2,1),
       lwd = c(2, 2, 2),
       lty = c(2, 1, 1))

lags = 18
par(mfrow=c(1,2))
acf(residuals_FS_MCOD6, lag.max=lags, plot=T , lwd=2 , xlab='', main='ACF de los residuales') 
pacf(residuals_FS_MCOD6, lag.max=lags, plot=T, lwd=2, xlab='', main='PACF de los residuales')

#Hacemos la prueba ADF sobre los residuales del modelo MCOD
adf10 = ur.df(residuals(FS_MCOD6), lag=1, type = "none"); plot(adf10)
summary(adf10) #Residuales estacionarios,

# NOTA: Casi siempre los residuales en un modelo MCOD presentará autocorrelación debido a que no se incluyen rezagos 
#       de la variable dependiente, de  manera que en esos casos es recomendable utilizar errores robustos tipo HAC.
#       En MCOD se incluyen adelantos y rezagos de la variable independiente, pero no de la variable dependiente, por 
#       lo que es usual que estos modelos presenten autocorrelación y sea necesario hacer la inferencia estadísticas
#       con errores robustos HAC

# 3.2 Estimación del modelo de corrección de errores ---- 

# MODELO DE CORRECIÓN DE ERRORES (VEC): Utilizaremos los betas estimados por 
# Introduciremos 3 rezagos de cada variable por supuesto. En realidad deberían comparar
# varios modelos con diferentes especificaciones por medio del AIC y determinar el mejor. La 
# inclusión del intercepto en el modelo de largo plazo no afecta el resultado.

# En modelo de corrección de errores se estiman dos ecuaciones, cada una utilizando como variable
# dependiente una serie diferente de las dos series que están cointegradas
# (una serie diferente por cada ecuación diferente)

# El término de corrección de error en el modelo es:
# L(TB10YS - parametro_cointegración * TB3MS, 1) que es el término que recoge
# la relación de largo plazo entre TB10YS y TB3MS. Los coeficientes que 
# acompañan al término de corrección de error en las dos ecuaciones del modelo
# se les conoce como coeficientes de velocidad de ajuste en la medida de que 
# miden la velocidad en la que las variables se ajustan a su "atractor" o 
# equilibrio de largo plazo cuando presentan desviaciones de este. 

# Para entender más a fondo el modelo de corrección de error revisar: 
# los capítulos 6.4 y 6.5 del Enders

# 3.2.1 Modelo de corrección de errores usando el parámetro de cointegración estimado por MCO ---- 

# Parámetro/vector de cointegración que se obtuvó empleando MCO
parametro_cointegración_MCO = coint_param_MCO

VEC_EQ1 <- dynlm(d(TB10YS) ~  L(TB10YS - parametro_cointegración_MCO * TB3MS,1) + L(d(TB3MS), 0:3) + L(d(TB10YS), 1:3));summary(VEC_EQ1) #El parámetro de velocidad de ajuste alpha tiene el signo esperado
VEC_EQ2 <- dynlm(d(TB3MS) ~  L(TB10YS - parametro_cointegración_MCO * TB3MS,1)+ L(d(TB3MS), 1:3) + L(d(TB10YS), 0:3));summary(VEC_EQ2) #El parámetro de velocidad de ajuste alpha tiene el signo esperado

# 3.2.2 Modelo de corrección de errores usando el parámetro de cointegración estimado por MCOD ---- 

# Parámetro/vector de cointegración que se obtuvó empleando MCO
parametro_cointegración_MCOD = coint_param_MCOD

  VEC_EQ3 <- dynlm(d(TB10YS) ~  L(TB10YS - parametro_cointegración_MCOD * TB3MS, 1) + L(d(TB3MS), 0:3) + L(d(TB10YS), 1:3));summary(VEC_EQ3) #El parámetro de velocidad de ajuste alpha tiene el signo esperado
VEC_EQ4 <- dynlm(d(TB3MS) ~  L(TB10YS - parametro_cointegración_MCOD * TB3MS, 1)+ L(d(TB3MS), 1:3) + L(d(TB10YS), 0:3));summary(VEC_EQ4) #El parámetro de velocidad de ajuste alpha tiene el signo esperado

# PASO 4: Validación de supuestos del modelo de corrección de errores ----

# En este caso, vamos a hacer la validación de supuestos del modelo de corrección
# de errores donde reemplazamos como coeficiente de cointegración el obtenido por MCOD, 
# es decir, parametro_cointegración_MCOD

# Cálculo de los residuales del modelo: 
residuales_VEC_EQ3 = residuals(VEC_EQ3)
residuales_VEC_EQ4 = residuals(VEC_EQ4)

#Analizamos que los residuales sean estacionarios: 

# Ecuación VEC_EQ3
adf_VEC_EQ3 = ur.df(residuales_VEC_EQ3, lag=1, type = "none"); plot(adf_VEC_EQ3)  
summary(adf_VEC_EQ3) # Residuales estacionarios. 

# Ecuación VEC_EQ4
adf_VEC_EQ4 = ur.df(residuales_VEC_EQ4, lag=1, type = "none"); plot(adf_VEC_EQ4)  
summary(adf_VEC_EQ4) #Residuales estacionarios.

# De la preuba de ADF aplicado a estos residuales hay que tener cuidado en utilizar los valores criticos correctos dado que al incluir 
# el terimino de correccion de error se están incluyendo estimaciones de una primera etapa lo que hace que los valores criticos para una ADF
# aplicada a los residuales del modelo de corrección de errores pueden cambiar. Los valores criticos para usar son los mismos que se usan para 
# la prueba de cointegracion de Engle-Granger y están en el manual suplementario del Enders (Tabla C). No obstante, dicho test no es para probar 
# que los residuales son ruido blanco sino que son  estacionarios en media, lo cual es una consecuencia de que haya cointegración. 

# Test para probar que los residuales son ruido blanco
# Selección del número de lags para la prueba
length(residuales_VEC_EQ3)/4 # aproximdamente 60

# Test Box-Pierce para autocorrelación en los residuales
Box.test(residuales_VEC_EQ3,lag=60, type = c("Box-Pierce")) #No rechazo H0, se cumple el supuesto. 
Box.test(residuales_VEC_EQ3,type='Box-Pierce',lag=20) #No rechazo H0, se cumple el supuesto. 
Box.test(residuales_VEC_EQ3,type='Box-Pierce',lag=30) #No rechazo H0,  se cumple el supuesto.

Box.test(residuales_VEC_EQ4,lag=60, type = c("Ljung-Box")) #NO rechazo H0, se cumple el supuesto. 
Box.test(residuales_VEC_EQ4,type='Ljung-Box',lag=20) #NO rechazo H0, se cumple el supuesto. 
Box.test(residuales_VEC_EQ4,type='Ljung-Box',lag=30) #NO rechazo H0,  se cumple el supuesto.

# En tanto los residuales no están autocorrelacionados en ninguna ecuación, deberían validar los demás supuestos.

# A diferencia de MCOD, la inclusión de rezgos de la variable dependiente en la ecaución, hace que el modelo de corrección de errores
# sí capture las estructuras de correlación de carácter autorregresivo que allí no se incorporan que pueden estar presentes en la serie
# cosa que no puede hace bien el modelo MCOD en la medida que solo tiene incorporados rezagos de la variable independiente 

# Nota: Es importante tener en cuenta que: 
## 1. MCOD: Está diseñado para estimar el vector/parámetro de cointegración. El proposito principal del modelo MCOD es calcular ese
##          parámetro de cointegración que luego va a ser utilizado/empleado en el modelo de correción de errores que se estima posteriormente, 
##          luego de conocer el valor del parámetro de cointegración. Por tanto, MCOD se utiliza para saber cuál es el valor del parámetro de 
##          cointegración, si ese parámetro es estadísticamente significativo, y empleando un test de cointegración de Engle-Granger establecer
##          si las series están cointegradas
##  2. Modelo de corrección de errores: Se estiman luego de haber estimado el parámetro de cointegración utilizando MCOD y haber establecido 
##     de que en efecto las series están cointegradas mediante un test de cointegración de Engle-Granger. Nos interesan, en particular los
##     coeficientes que acompañana el término de error en las ecuaciones del modelo en la medida de que dan información sobre la velocidad
##     en la que se ajustan las variables luego de desviaciones a su atractor o equilibrio de largo plazo


# 2. PPP

#Ahora haremos un ejericio del libro de Enders para probar la PPA R=N*(P*/P)->  r= e + log(P*) - log(P)


#JAPANCPI is the Japanese price level and JAPANEX is the bilateral Japanese/U.S. exchange rate. 
#The starting date for all variables is January 1974 while the availability of the variables is such that most end near 
#the end of 2012. The price indices have been normalized to equal 100 in January 1973

PPA <- read_excel(file.choose())
attach(PPA)
View(PPA)

e = ts(log(JAPANEX), start=c(1974,1), frequency=12)
lp.j = ts(log(JAPANCPI), start=c(1974,1), frequency=12)  
lp.u = ts(log(USCPI), start=c(1974,1), frequency=12)

#METODOLOGÍA ENGLE & GRANGER.

#------
#Paso 1: Aplicaremos la prueba ADF y KPSS sobre cada una de las series.

## Prueba sobre el logaritmo de la tasa de cambio nominal

#Primero vamos a hacer una prueba de ADF con tendencia e intercepto.Los valores críticos de la prueba son sensibles a 
#la inclusión de términos determinísticos, de manera que hay que determinar si la serie tiene tendencia y/o intercepto. 

#El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi3 me dice si la tendecia es 
#significativa o no, y por tanto, si el el test de raíz unitaria debería incluir o no tendencia. 
adf11= ur.df(e, lags=9, type = "trend")
summary(adf11)
plot(adf11)
#El tau nos dice que la serie tiene al menos una raíz unitaria, mientras el phi3 nos dice que la tendencia 
#no es significativa. Por lo tanto, vamos a mirar únicamente la prueba con intercepto.

#El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi2 me indica si la deriva es
#significativa, y por consiguiente, si se debe incluir en el test de raíz unitaria. 
adf12= ur.df(e, lags=9, type = "drift")
summary(adf12)
plot(adf12)
#Los resultados indican que la serie tiene al menos una raíz unitaria. El phi2, por su parte, indica que 
#la deriva de la serie no es significativa, por tanto, debe hacerse una prueba sin términos determinísticos.

#Esta es la correcta especificación de la prueba dado que los términos determinísticos no son significativos. 
adf13=ur.df(e, lags=9, type = "none")
summary(adf13)
plot(adf13)
#Claramente se evidencia que la serie tiene al menos una raíz unitaria, en tanto no se rechaza la hipótesis nula. 
#Noten la importancia de determinar si la serie tiene términos detemrminísticos, pues el valor calculado en cada
#especificación de la prueba cambió de forma importante.

#Hacemos la prueba KPSS cuya hipótesis nula es que la serie es estacionaria, la cual es totalmente contraria a la ADF. 
kp3= ur.kpss(e, use.lag = 9, type = "mu") #el mu nos indica que es una prueba sin términos determin?sticos.
summary(kp3)
plot(kp3)
#Claramente rechazamos la hipótesis nula de estacionariedad, así que las serie no es estacionaria. 

# Prueba sobre el logaritmo del nivel internacional de precios

#Primero vamos a hacer una prueba de ADF con tendencia e intercepto.Los valores críticos de la prueba son sensibles a 
#la inclusión de términos determinísticos, de manera que hay que determinar si la serie tiene tendencia y/o intercepto. 

#El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi3 me dice si la tendecia es 
#significativa o no, y por tanto, si el el test de raíz unitaria debería incluir o no tendencia. 
adf14= ur.df(lp.j, lags=8, type = "trend")
summary(adf14)
plot(adf14)
#La serie según esta prueba es estacionaria en torno a una tendencia determinística. 

#Hacemos la prueba KPSS cuya hipótesis nula es que la serie es estacionaria, la cual es totalmente contraria a la ADF. 
kp4=ur.kpss(lp.j, use.lag = 8, type = "tau") #el tau nos indica que es una prueba con términos determinísticos.
summary(kp4)
plot(kp4)
#Claramente rechazamos la hipótesis nula de estacionariedad, así que las serie no es estacionaria. Nos inclinamos por
#esta prueba al evaluar la gráfica de la serie y sus residuales.


# Prueba sobre el logaritmo del nivel nacional de precios

#Primero vamos a hacer una prueba de ADF con tendencia e intercepto.Los valores críticos de la prueba son sensibles a 
#la inclusión de términos determinísticos, de manera que hay que determinar si la serie tiene tendencia y/o intercepto. 

#El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi3 me dice si la tendecia es 
#significativa o no, y por tanto, si el el test de raíz unitaria debería incluir o no tendencia. 
adf15 = ur.df(lp.u,lags=7, type = "trend")
summary(adf15)
plot(adf15)

#La serie según esta prueba no es estacionaria en torno a una tendencia determinística. 

#Hacemos la prueba KPSS cuya hipóesis nula es que la serie es estacionaria, la cual es totalmente contraria a la ADF. 
kp5=ur.kpss(lp.u, use.lag = 7, type = "tau") #el tau nos indica que es una prueba con términos determinísticos.
summary(kp5)
plot(kp5)
#Claramente rechazamos la hipótesis nula de estacionariedad, así que las serie no es estacionaria. 


#Graficamos
x11()
autoplot(e, col="red", main = "logaritmo de la tasa de cambio nominal",xlab = "Fecha", ylab="", lwd=2)
autoplot(lp.j, col="red", main = "logaritmo del indice de precios de Japón",xlab = "Fecha", ylab="", lwd=2)
autoplot(lp.u, col="red", main = "logaritmo del indice de precios de USA",xlab = "Fecha", ylab="", lwd=2)


#------
#Paso 2: Estimación de los residuales de la regresión en niveles.

#La teoría económica sugiere que el tipo de cambio real bajo PPA debe ser uno, así que al sacar logaritmos nos queda e = log(p)-log(p*) 

R.1 <- dynlm(e ~ lp.j + lp.u) 
summary(R.1)

#Obtenemos los residuales
res <- residuals(R.1)

#Graficamos los residuales y analizamos su ACF y PACF
plot.ts(res)

lags=48
par(mfrow=c(1,2))
acf(res,lag.max=lags,plot=T,lwd=2,xlab='',main='ACF de los residuales') 
pacf(res,lag.max=lags,plot=T,lwd=2,xlab='',main='PACF de los residuales')

#Haremos la prueba ADF sin términos determinísticos.
adf16=ur.df(res, lags=12,type = "none") #Los residuales son estacionarios: hay cointegración. 
summary(adf16)
plot(adf16)


# Recordar que los valores criticos para la prueba de engle-granger son distintos a los valores
# criticos de una ADF convencional dado que hubo una estimacion anterior de primera etapa.
# Dichos valores se encuentran en la tabla del Enders, incluyendo 3 variables en la relación de cointegración

# Usando la funcion coef.test del paquete aTSA se obtiene: (hay que constuir una matriz para describir
# que hay dos variables regresoras o inputs)
coint.test(e, cbind(lp.j, lp.u),nlag = 12)

#------
#Paso 3: Modelo de Corrección de errores.
#Para este ejemplo solo estimaremos la primera ecuación. 
### Introduciremos 5 rezagos de cada variable por supuesto. En realidad deberían comparar
### varios modelos con diferentes especificaciones por medio del AIC y determinar el mejor


#Sin incluir la constante en el término de corrección de error. 
VEC_EQ1 <- dynlm(d(e) ~  L(e-0.10420*lp.j -0.76823*lp.u ) + L(d(lp.j), 0:5) + L(d(lp.u), 0:5) + L(d(e), 1:5));summary(VEC_EQ1) #El parámetro de velocidad de ajuste alpha tiene el signo esperado
#Incluyendo la constante en el término de corrección de error.
VEC_EQ1.cons <- dynlm(d(e) ~  L(e-9.97459 -0.10420*lp.j  -0.76823*lp.u ) + L(d(lp.j), 0:5) + L(d(lp.u), 0:5) + L(d(e), 1:5));summary(VEC_EQ1.cons) #El parámetro de velocidad de ajuste alpha tiene el signo esperado

#PASO 4: VALIDACI?N

#Analizamos que los residuales sean estacionarios.
summary(ur.df(residuals(VEC_EQ1), lags=3, type = "none")) #Residuales estacionarios.
summary(ur.kpss(residuals(VEC_EQ1), type="mu", use.lag = 3)) #Residuales estacionarios.

# De la preuba de ADF aplicado a estos residuales hay que tener cuidado en utilizar los valores críticos correctos dado que al incluir 
#el término de corrección de error se están incluyendo estimaciones de una primera etapa, lo que hace que los valores criticos para una ADF
# aplicada a los residuales del modelo de corrección de errores puedan cambiar.Los valores críticos para usar son los mismos que se usan para 
#la prueba de cointegracion y están en el Enders.No obstante, dicho test no es para probar que los residuales son ruido blanco sino que son 
#estacionarios en media, lo cual es una consecuencia de que haya cointegración. 

# Test Box-Pierce para autocorrelaci?n en los residuales
Box.test(residuals(VEC_EQ1),lag=117, type = c("Box-Pierce")) #rechazo H0, no se cumple el supuesto. 
Box.test(residuals(VEC_EQ1),lag=60, type= c("Box-Pierce"))  #rechazo H0, no se cumple el supuesto. 
Box.test(residuals(VEC_EQ1),type='Box-Pierce',lag=20) #rechazo H0, no se cumple el supuesto. 
Box.test(residuals(VEC_EQ1),type='Box-Pierce',lag=30) # rechazo H0,no  se cumple el supuesto.

Box.test(residuals(VEC_EQ1),lag=117, type = c("Ljung-Box")) #rechazo H0, no se cumple el supuesto. 
Box.test(residuals(VEC_EQ1),lag=60, type = c("Ljung-Box")) #rechazo H0, no se cumple el supuesto. 
Box.test(residuals(VEC_EQ1),type='Box-Pierce',lag=20) # rechazo H0, no se cumple el supuesto. 
Box.test(residuals(VEC_EQ1),type='Box-Pierce',lag=30) #rechazo H0,  no se cumple el supuesto. 

#En tanto no se satisface el supuesto de no autocorrelación, tenemos que volver a la etapa de estimación e incluir más rezagos. Si fuese un modelo de
#MCOD, es natural que no se satisfaga el supuesto, por lo cual se utilizaría errores tipo HAC. Para VEC es necesario introducir rezagos adicionales, sobre
#todo si las series son mensuales debido a la persistencia de la correlación en este tipo de series. 