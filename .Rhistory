num_bins = 30, coef_b = cluster_bootstrap_df$b0, mean_b = mean_b0_cluster_boot,
b_muestra_estimada_original = reg1_sum$estimate[1], b_original = b[1]); densidad_b0
densidad_b1 = histogram_b(df = boot_conv_df, titulo = "Distribución empírica de b1 generados por cluster bootstrapping",
x_lab = "Valores de b1 simulados por cluster bootstrapping", y_lab = "", y_upper_limit = 12.5,
num_bins = 30, coef_b = cluster_bootstrap_df$b1, mean_b = mean_b1_cluster_boot,
b_muestra_estimada_original = reg1_sum$estimate[2], b_original = b[2]); densidad_b1
densidad_b2 = histogram_b(df = boot_conv_df, titulo = "Distribución empírica de b2 generados por cluster bootstrapping",
x_lab = "Valores de b2 simulados por cluster bootstrapping", y_lab = "", y_upper_limit = 14,
num_bins = 30, coef_b = cluster_bootstrap_df$b2, mean_b = mean_b2_cluster_boot,
b_muestra_estimada_original = reg1_sum$estimate[3], b_original = b[3]); densidad_b2
# Renombre cada una de las columnas de la matriz de información
colnames(mat_info) = c("coef. (1)", "Trad. E.E. (2)",
"Trad. p-valor (3)", "Boot. E.E. (4)",
"Boot. p-valor (5)", "x10 E.E. (6)",
"x10 p-valor (7)", "Clúster E.E. (8)",
"Clúster p-valor (9)", "Clúster Boot. E.E. (10)",
"Clúster Boot. p-valor (11)", "Wild boot. p-valor (12)")
# Transformación de la matriz de información a un Dataframe
base_exportar = as.data.frame(mat_info) %>%
mutate(Información = c("b0",
"b1",
"b2",
"Obs.",
"Clústeres")) %>%
select(Información, !Información); base_exportar
# Exportación del dataframe con la información de las diferentes simulaciones de bootstrap a una tabla de latex
xtable(base_exportar, type = "latex")
# Visualización de la matriz mat_info hasta esta etapa del proceso
mat_info
4e-3
source("~/Documents/GitHub/semestre8_git/Econometría_avanzada/Talleres_econometria_avanzada/Taller3/Scripts/Scripts_R/punto3.R", echo=TRUE)
mat_info
source("~/Documents/GitHub/semestre8_git/Econometría_avanzada/Talleres_econometria_avanzada/Taller3/Scripts/Scripts_R/punto3.R", echo=TRUE)
mat_info
log(2.718)
log(12)
log(41.6) / log(12)
log(58.8) / log(24)
20.8 * 2
(29.4 - 20.8) * 2
(58.8 - 41.6) * 2
17.2 * 2
5 / sqrt(5)
10 / sqrt(5)
5 / sqrt(12)
10 / sqrt(12)
5 / sqrt(12)
10 / sqrt(12)
5 / sqrt(24)
10 / sqrt(24)
2.041421 / 1.020621
5 / (5)^(-3)
10 / (5)^(-3)
625 * 2
pmg1 = 41.6
pmg2 = 58.8
l1 = 12
l2 = 24
num = log(pmg1/pmg2)
denom = log(l2/l1)
num/denom
num
denom
pmg1
denom = log(l1/l2)
num/denom
41.6 / sqrt(12)
sqrt(24) * 12
12/ sqrt(60)
12/ (2 * sqrt(60))
6 / (sqrt(60))
120/37
36/37
(36/37) * 120
la = 120/37
lm = (120 - 120/37)
lm
la
la + lm
12 * (la)^(1/2)
6 * (lm)^(1/2)
12 * 60^1/2
12 * sqrt(60)
12 * 60^1/2
12 * 60^(1/2)
12 * sqrt(60)
12 * sqrt(la)
6 * sqrt(lm)
6 * sqrt(60)
6 * (1/(sqrt(la)))
36 * (1/(sqrt(lm)))
log(41.6/58.8) / log(12/24)
lm
##____________________________________________________________________________________
##____________________________________________________________________________________
#       UNIVERSIDAD NACIONAL DE COLOMBIA - FACULTAD DE CIENCIAS ECON?MICAS
#                         ECONOMETRIA II - 2022-I
#           Monitoria: Cointegración - Metodología Engle & Granger.
##____________________________________________________________________________________
##_____________________________________________________________________________________
## Limpiar el entorno de objetos
remove(list = ls())
# Se importan algunos paquetes que van a utilizar a lo largo de la metodología
# Paquetes de proposito general
library(tidyverse) # Conjunto de paquetes fundamental para manejo de datos enR
library(broom) # Paquete para analizar modelos en R
library(readxl) # Para importar archivos excel en R
# Paquetes de series de tiempo
library(dynlm) # Paquete para realizar MCOD (DOLS) y modelos de corrección de error en R
library(urca) # Paquete para realizar pruebas de raíz unitaria y cointegración en R
library(car) # Para usar la función qqPlot
library(aTSA)
library(forecast)
library(tseries)
library(rlang)
# Notas sobre cointegración:
# En economía, nos interesa poder analizar las relaciones económicas entre diferentes
# variables económicas, y en particular, en macroeconomía nos interesa estudiar
# las relaciones que se pueden establecer entre variables agregadas.
# La metodología de cointegración, nos permite analizar relaciones de largo plazo
# entre dos o más variables analizando la tendencia o comportamiento común entre éstas,
# y en metadologías más generales como lo son la metodología de Johansen
# se pueden estudiar dos o más relaciones de cointegración entre varias variables.
# La cointegración entre dos o más variables, implica la existencia de una tendencia
# estocástico común entre dichas variables, lo que hace que éstas tiendan a tener un
# movimiento común a largo plazo alrededor de un "atractor" o punto de equilibro que
# determina de algún modo el movimiento común de la variables alrededor de éste.
# Existen varias metodologías de cointegración en la literatura:
## ARDL
## Metodología de Engle-Granger
## Metodología de Johansen
# En el curso se estudiaran la metodología de Engle-Granger (que es el procedimiento
# que veremos en el presente Script) y metodología de Johansen (que lo veremos luego
# de ver la metodología de VAR)
# La metodología de cointegración ha tenido una fuerte acogida en la literatura de
# macroeconomía, en particular, los académicos y bancos centrales la han empleado
# para estudiar de manera exitosa las relaciones entre variables cambiarias y monetarias
# con el fin de formular teoría económica y orientar mejor el diseño de política pública.
# Ejemplos de cointegración en la literatura:
## Hipótesis del ingreso permanente de Friedman
## Ley de precio único
## Unbiased forward rate hypothesis (Insesgadez en la tasa forward como predictor de la tasa spot futura de una moneda)
## Movimiento conjunto de una casta de divisas (e.g. de las principales divisas, de las monedas de AL, demás)
## Hipótesis de expectativas de la estructura temporal de la tasa de interés (ejemplo 1 del script)
## Paridad de poder adquisitivo (PPP) y arbitraje en el mercado de bienes (ejemplo 2 del script)
# Revisar el capítulo 6.1 del Enders para profundizar sobre algunos ejemplos de
# cointegración entre variables que se puede encontrar en la literatura
# 1. Expectations hypothesis: Hipótesis de expectativas de la estructura temporal de la tasa de interés  ----
# En economía financiera, existe la concepción de que las tasas de interés de corto
# y de largo plazo de los bonos de un mismo país tienden a tener un movimiento común.
# Bono, entendido como ese instrumento/vehículo de financiación que utilizan los países
# para conseguir financiación extranjera
# El análisis se centra en la explicación de la famosos Yield Curve de dichos bonos
# y en explicar su dinámica así como su pendiente
# Existen diferentes teorías que intentan explicar este comportamiento común de las
# tasa de interés de dichos bonos.
# Modelos de tasas de interés:
### 1. La teoría de expectativas en la estructura temporal:
###    Teoría más famosa y más comúnmente empleada pero de la que se sabe que tiene
###    complicaciones o está incompleta)
### 2. Liquidity preference hypothesis: La teoría por la preferencia por la liquidez
###     argumenta que los inversionistas exigen una "prima" adicional de retorno
###     para invertir en bonos de LP dado que los consideran más riesgosos que los bonos
###     de corto plazo
### 3. Modelos dinámicos: Vasicek, Cox-Ingersoll-Ross
# En general, se espera que las tasas de largo plazo sean mayores a las tasas de corto
# plazo y por ende una pendiente positiva de la famosa Yield Curve. Cuando la Yield
# Curve se invierte, entonces las tasas de CP son mayores a las tasas de LP. Cuando lo
# anterior ocurre, los inversionistas y agentes del mercado suelen asociar a dicha
# inversión en la Yiled Curve como un presagio de que algo va a ocurrir en la economía
# algunas personas inclusive asocian a dicha inversión de la Yield Curve como una
# señal de que una economía va a entrar en recesión (aunque este "hecho estilizado" no
# siempre se cumple o se observa en la realidad)
# El presente es un ejemplo del libro Introduction to econometrics with R de Hanck, Arnold, Gerber y Schmelzer.
# Disponible en el siguiente link: https://www.econometrics-with-r.org/16-3-cointegration.html
# Nota: https://www.econometrics-with-r.org/ es un libro online bastante interesante, en la medida que tiene los códigos en R
#       adaptados a los ejemplos del libro Introduction to Econometrics by Stock and Watson (2015) por lo que van a poder
#       encontrar material de muy buena calidad en diversos temas de econometría en general, por lo que se les recomienda bastante
#       que revisen los temas del libro porque podrían encontrar códigos de su interés.
# Para este ejemplo veremos la relacion entre la tasa de interés
# de corto plazo (Treasury bills a 3 meses) y la tasa de interés de largo plazo (Treasury
# bonds a 10 años) de los Estados Unidos. En caso de estar cointegradas las series,
# se esperaría que el spread entre estas dos tasas, que es básicamente la diferencia
# entre las dos tasas, sea una serie estacionaria.
# En algunos contextos, se utiliza la Treasury bills a 3 meses como la tasa libre de
# riesgo mientras que en otros se emplea la Treasury bonds a 10 años como la tasa libre de
# riesgo
# Importación de la base de datos
# La base de datos USMacroSWQ contiene diferentes series de tiempo relacionadas con
# variables macroeconómicas de interés de los Estados Unidos. En particular, contiene
# la serie histórica de las tasas de interés de los bonos del Tesoro de los EE.UU.
# A 3 meses (TB3MS), a un año (GS1) y a 10 años (GS10)
USMacroSWQ <- read_xlsx(file.choose(),sheet = 1,col_types = c("text", rep("numeric", 9)))
# Formato de la columna fecha (date)
USMacroSWQ$...1 <- as.yearqtr(USMacroSWQ$...1, format = "%Y:0%q")
# Ajustamos nombres de las columnas
colnames(USMacroSWQ) <- c("Date", "GDPC96", "JAPAN_IP", "PCECTPI",
"GS10", "GS1", "TB3MS", "UNRATE", "EXUSUK", "CPIAUCSL")
# Visualización de la base de datos
glimpse(USMacroSWQ)
# Tasa de interés 3-months Treasury bills
TB3MS = ts(USMacroSWQ$TB3MS, start = c(1957,1), end = c(2013,4), frequency = 4)
# Tasa de interés 10-years Treasury bonds
TB10YS = ts(USMacroSWQ$GS10,start = c(1957,1), end = c(2013,4), frequency = 4)
# Se analiza el comportamiento gráfico de las dos tasas
x11()
plot(merge(as.zoo(TB3MS), as.zoo(TB10YS)),
plot.type = "single",
lty = c(2, 1),
lwd = 2,
xlab = "Año",
ylab = "Porcentaje anual",
ylim = c(-5, 17),
main = "Tasas de interés")
# Ahora se grafica el spread de las dos tasas en la misma gráfica.
lines(as.zoo(TB10YS-TB3MS),
col = "steelblue",
lwd = 2,
xlab = "Año",
ylab = "Porcentaje anual")
# Se añade la leyenda
legend("topright",
legend = c("TB3MS", "TB10YS", "Spread"),
col = c("black", "black", "steelblue"),
lwd = c(2, 2, 2),
lty = c(2, 1, 1))
# Del anterior gráfico es posible concluir que las series posiblemente están cointegradas, en tanto:
# las series en nivel aparentemente son I(1) (aparentan tener una tendencia estocástica común), y finalmente,
# el spread entre ellas parece ser estacionario (la combinación lineal entre ambas parece eliminar la tendencia estocástica)
# A nivel económico la anterior gráfica da bastante información relevante. Observar el
# comportamiento de las tasas de interés de los Estados Unidos dice bastante sobre la
# política monetaria que condujó la FED y el estado la economía norteaméricana. Por ejemplo,
# Se puede observar como en los 80s Volcker aumentó fuertemente las tasas de interés
# de EE.UU. para combatir la inflación, lo que tuvó fuertes consecuencias en crecimiento
# y pagos de la deuda en los países de América Latina. También, muestra las bajas tasas
# de interés de la FED luego de la crisis sub-prime del 2008
###
# Metodología Engle & Granger para la hipótesis de expectativas:
###
# Paso 1: Uso de la prueba ADF y KPSS sobre las series ----
# 1.1 ADF y KPSS sobre la tasa de interés de los T-Bills a 3 meses ----
# Primero vamos a hacer una prueba de ADF con tendencia e intercepto. Los valores críticos de la prueba son sensibles a
# la inclusión de términos determinísticos, de manera que hay que determinar si la serie tiene tendencia y/o intercepto.
# El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi3 me dice si la tendecia es
# significativa o no, y por tanto, si el el test de raíz unitaria debería incluir o no tendencia.
adf1 = ur.df(TB3MS, lags=4, type = "trend"); plot(adf1)
summary(adf1)
# El tau nos dice que la serie tiene al menos una raíz unitaria, mientras el phi3 nos dice que la tendencia
# no es significativa. Por lo tanto, vamos a mirar únicamente la prueba con intercepto.
#El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi1 me indica si la deriva es
#significativa, y por consiguiente, si se debe incluir en el test de raíz unitaria.
adf2 = ur.df(TB3MS, lags=4, type = "drift"); plot(adf2)
summary(adf2)
#Los resultados indican que la serie tiene al menos una raíz unirtaria. El phi1, por su parte, indica que
#la deriva de la serie no es significativa, por tanto, debe hacerse una prueba sin deriva
#Esta es la correcta especificación de la prueba dado que los términos determinísticos no son significativos.
adf3 = ur.df(TB3MS,lags=4, type = "none"); plot(adf3)
summary(adf3)
#Claramente se evidencia que la serie tiene al menos una raíz unitaria, en tanto no se rechaza la hipótesis nula.
#Noten la importancia de determinar si la serie tiene términos detemrminísticos, pues el valor calculado en cada
#especificación de la prueba cambió de forma importante.
# Hay dos tipos de pruebas importantes que se emplea comúnente en la literatura para
# inverstigar si una serie tiene o no tiene raíz unitaria:
## 1. La familia de las pruebas tipo ADF donde la hipótesis nula es no estacionariedad
## 2. La familia de pruebas donde la hipótesis nula es estacionariedad. La más famosas de este tipo de prueba
##    es la prueba KPSS
# Nota: En la práctica es muy usual emplear al menos estas dos tipos de prueba para verificar la estacionariedad
#       de una serie, de tal forma que se puedea obtener una diagnóstico más profundo del comportamiento de la serie
#       y de si presenta o no una tendencia estocástica la serie de tiempo.
# Hacemos la prueba KPSS cuya hipótesis nula es que la serie es estacionaria, la cual es totalmente contraria a la ADF.
# Se toman 4 rezagos porque fueron los mismos utilizados en las pruebas ADF
kp1 = ur.kpss(TB3MS, use.lag = 4, type = "mu") #el mu nos indica que es una prueba sin términos determinísticos.
summary(kp1)
# Claramente rechazamos la hipótesis nula de estacionariedad, así que la serie de la tasa
# de interés de los treasury bills a 3 meses no es estacionaria.
# 1.1 ADF y KPSS sobre la tasa de interés de los T-Bonds a 10 años ----
# Primero vamos a hacer una prueba de ADF con tendencia e intercepto. Los valores críticos de la prueba son sensibles a
# la inclusión de términos determinísticos, de manera que hay que determinar si la serie tiene tendencia y/o intercepto.
# El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi3 me dice si la tendecia es
# significativa o no, y por tanto, si el el test de raíz unitaria debería incluir o no tendencia.
adf4 = ur.df(TB10YS,lags=1, type = "trend"); plot(adf4)
summary(adf4)
# El tau nos dice que la serie tiene al menos una raíz unitaria, mientras el phi3 nos dice que la tendencia
# no es significativa. Por lo tanto, vamos a mirar únicamente la prueba con intercepto.
# El tau me dice si la serie tiene o no al menos una raíz unitaria. El phi1 me indica si la deriva es
# significativa, y por consiguiente, si se debe incluir en el test de raíz unitaria.
adf5 = ur.df(TB10YS, lags=1, type = "drift"); plot(adf5)
summary(adf5)
# Los resultados indican que la serie tiene al menos una raíz unitaria. El phi2, por su parte, indica que
# la deriva de la serie no es significativa, por tanto, debe hacerse una prueba sin deriva
#Esta es la correcta especificación de la prueba dado que los términos determinísticos no son significativos.
adf6 =  ur.df(TB10YS, type = "none"); plot(adf6)
summary(adf6)
# Claramente se evidencia que la serie tiene al menos una raíz unitaria, en tanto no se rechaza la hipótesis nula.
# Noten la importancia de determinar si la serie tiene términos detemrminísticos, pues el valor calculado en cada
# especificación de la prueba cambió de forma importante.
#Hacemos la prueba KPSS cuya hipótesis nula es que la serie es estacionaria, la cual es totalmente contraria a la ADF.
kp2 = ur.kpss(TB10YS, use.lag = 1, type = "mu") #el mu nos indica que es una prueba sin términos determinísticos.
summary(kp2)
plot(kp2)
# Claramente rechazamos la hipótesis nula de estacionariedad, así que las serie tiene al menos una raíz unitaria.
#Hacemos la prueba ADF sobre las series diferenciadas para confirmar que son I(1)
adf8 = ur.df(diff(TB3MS), lag=2, type = "none");plot(adf8); summary(adf8) #Estacionaria.
adf7 = ur.df(diff(TB10YS), lag=1, type = "none");plot(adf7); summary(adf7) #Estacionaria
# Paso 2: Estimación de los residuales de la regresión en niveles ----
#La teoría económica (teoría de expectativas de la estructura tempora de las tasas de interés)
# sugiere que el vector de cointegración es -1. Para corroborar lo anterior empíricamente,
# se empieza encontrando el valor del vector de cointegración.
# El comando dynlm:
?dynlm
# Si TB3MS y TB10YS son series I(1) y además están cointegradas, se puede estimar una regresión en niveles:
# El estimador de MCO de la regresión en niveles es consistente cuando yt y zt están cointegradas
FS_EGADF <- dynlm(TB10YS ~ TB3MS)
summary(FS_EGADF)
# Se obtienen los residuales de la regresión
z_hat <- residuals(FS_EGADF)
# Graficamos los residuales y analizamos su ACF y PACF
x11()
plot.ts(z_hat)
lags=36
par(mfrow=c(1,2))
acf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='ACF de los residuales')
pacf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='PACF de los residuales')
#Haremos la prueba ADF sin términos determinísticos.
adf9 = ur.df(z_hat,lags=6,type = "none"); plot(adf9); summary(adf9) #Los residuales son estacionarios: hay cointegración.
lags=36
par(mfrow=c(1,2))
acf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='ACF de los residuales')
pacf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='PACF de los residuales')
#Haremos la prueba ADF sin términos determinísticos.
adf9 = ur.df(z_hat,lags=1,type = "none"); plot(adf9); summary(adf9) #Los residuales son estacionarios: hay cointegración.
#Haremos la prueba ADF sin términos determinísticos.
adf9 = ur.df(z_hat,lags=1,type = "none"); plot(adf9); summary(adf9) #Los residuales son estacionarios: hay cointegración.
# El comando coint.test del paquete aTSA permite realizar los dos pasos de la prueba de cointegración
coint.test(TB10YS, TB3MS, nlag=1)
# El comando coint.test del paquete aTSA permite realizar los dos pasos de la prueba de cointegración
coint.test(TB10YS, TB3MS, nlag=6)
# También es posible ejecutar la prueba de cointegración de engle-granger de manera automática de una vez
# El comando coint.test del paquete aTSA permite realizar los dos pasos de la prueba de cointegración
coint.test(TB10YS, TB3MS)
# También es posible ejecutar la prueba de cointegración de engle-granger de manera automática de una vez
# El comando coint.test del paquete aTSA permite realizar los dos pasos de la prueba de cointegración
summary(coint.test(TB10YS, TB3MS))
hola = coint.test(TB10YS, TB3MS)
summary(hola)
type(hola)
class(hola)
plot(hola)
# También es posible ejecutar la prueba de cointegración de engle-granger de manera automática de una vez
# El comando coint.test del paquete aTSA permite realizar los dos pasos de la prueba de cointegración
coint.test(TB10YS, TB3MS)
# numero de datos a la hora de realizar el test de cointegracion
length(TB10YS)
FS_MCOD1 <- dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-1:1)); summary(FS_MCOD1)
FS_MCOD1 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-1:1)); summary(FS_MCOD1)
FS_MCOD2 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-2:2)); summary(FS_MCOD2)
FS_MCOD3 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-3:3)); summary(FS_MCOD3)
FS_MCOD4 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-4:4)); summary(FS_MCOD4)
FS_MCOD5 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-5:5)); summary(FS_MCOD5)
FS_MCOD6 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-6:6)); summary(FS_MCOD6)
# Se selecciona el modelo que minimice el AIC
cbind(AIC(FS_MCOD1), AIC(FS_MCOD2),AIC(FS_MCOD3),AIC(FS_MCOD4),AIC(FS_MCOD5),AIC(FS_MCOD6)) #Elegimos 6 rezagos y adelantos, en tanto tuvo el menor AIC
summary(FS_MCOD6)
#Graficamos el spread que nos dice la teoría junto con el estimado
x11()
plot(merge(as.zoo(TB10YS-TB3MS), as.zoo(residuals(FS_MCOD6))),
plot.type = "single",
lty = c(2, 1),
lwd = 2,
ylim = c(-5, 5),
xlab = "Año",
ylab = " ",
main = "Diferencias")
legend("bottomright",
legend = c("Spread","MCOD"),
col = c(2,1),
lwd = c(2, 2, 2),
lty = c(2, 1, 1))
#Hacemos la prueba ADF sobre los residuales del modelo MCOD
adf10 = ur.df(residuals(FS_MCOD6), lag=1, type = "none"); plot(adf10)
#Hacemos la prueba ADF sobre los residuales del modelo MCOD
adf10 = ur.df(residuals(FS_MCOD6), lag=1, type = "none"); plot(adf10)
summary(adf10) #Residuales estacionarios,
# Si TB3MS y TB10YS son series I(1) y además están cointegradas, se puede estimar una regresión en niveles:
# El estimador de MCO de la regresión en niveles es consistente cuando yt y zt están cointegradas
FS_EGADF <- dynlm(TB10YS ~ TB3MS)
summary(FS_EGADF)
# Se obtienen los residuales de la regresión
z_hat <- residuals(FS_EGADF)
# Graficamos los residuales y analizamos su ACF y PACF
x11()
plot.ts(z_hat)
lags = 24
par(mfrow=c(1,2))
acf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='ACF de los residuales')
pacf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='PACF de los residuales')
lags = 20
par(mfrow=c(1,2))
acf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='ACF de los residuales')
pacf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='PACF de los residuales')
lags = 18
par(mfrow=c(1,2))
acf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='ACF de los residuales')
pacf(z_hat,lag.max=lags,plot=T,lwd=2,xlab='',main='PACF de los residuales')
# Se calculan los residuales del modelo FS_MCOD6:
residuals_FS_MCOD6 = residuals(FS_MCOD6)
x11()
plot(merge(as.zoo(TB10YS-TB3MS), as.zoo(residuals_FS_MCOD6)),
plot.type = "single",
lty = c(2, 1),
lwd = 2,
ylim = c(-5, 5),
xlab = "Año",
ylab = " ",
main = "Diferencias")
legend("bottomright",
legend = c("Spread","MCOD"),
col = c(2,1),
lwd = c(2, 2, 2),
lty = c(2, 1, 1))
lags = 36
par(mfrow=c(1,2))
acf(residuals_FS_MCOD6,lag.max=lags,plot=T,lwd=2,xlab='',main='ACF de los residuales')
lags = 18
par(mfrow=c(1,2))
acf(residuals_FS_MCOD6, lag.max=lags, plot=T , lwd=2 , xlab='', main='ACF de los residuales')
pacf(residuals_FS_MCOD6, lag.max=lags, plot=T, lwd=2, xlab='', main='PACF de los residuales')
#Hacemos la prueba ADF sobre los residuales del modelo MCOD
adf10 = ur.df(residuals(FS_MCOD6), lag=1, type = "none"); plot(adf10)
summary(adf10) #Residuales estacionarios,
# Si TB3MS y TB10YS son series I(1) y además están cointegradas, se puede estimar una regresión en niveles:
# El estimador de MCO de la regresión en niveles es consistente cuando yt y zt están cointegradas
FS_EGADF <- dynlm(TB10YS ~ TB3MS)
summary(FS_EGADF)
tidy(FS_EGADF)
# También es posible encontrar los resultados de la regresión utilizando
# el comando tidy() del paquete broom
tidy_FS_EGADF = tidy(FS_EGADF)
# Parámetro/vector de cointegración calculado por MCO:
coint_param_MCO = tidy_FS_EGADF$estimate[2]
# Parámetro/vector de cointegración calculado por MCO:
coint_param_MCO = tidy_FS_EGADF$estimate[2]; coint_param_MCO
# Se elige el modelo con 6 rezagos y 6 adelantos, en tanto tuvo el menor AIC
summary(FS_MCOD6)
# También es posible encontrar los resultados de la regresión utilizando
# el comando tidy() del paquete broom
tidy_FS_MCOD6 = tidy(FS_MCOD6)
# Parámetro/vector de cointegración calculado por MCO:
coint_param_MCO = tidy_FS_MCOD6$estimate[2]; coint_param_MCO
# Si TB3MS y TB10YS son series I(1) y además están cointegradas, se puede estimar una regresión en niveles:
# El estimador de MCO de la regresión en niveles es consistente cuando yt y zt están cointegradas
FS_EGADF <- dynlm(TB10YS ~ TB3MS)
summary(FS_EGADF)
# También es posible encontrar los resultados de la regresión utilizando
# el comando tidy() del paquete broom
tidy_FS_EGADF = tidy(FS_EGADF)
# Parámetro/vector de cointegración calculado por MCO:
coint_param_MCO = tidy_FS_EGADF$estimate[2]; coint_param_MCO
FS_MCOD1 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-1:1)); summary(FS_MCOD1)
FS_MCOD2 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-2:2)); summary(FS_MCOD2)
FS_MCOD3 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-3:3)); summary(FS_MCOD3)
FS_MCOD4 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-4:4)); summary(FS_MCOD4)
FS_MCOD5 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-5:5)); summary(FS_MCOD5)
FS_MCOD6 = dynlm(TB10YS ~ TB3MS + L(d(TB3MS),-6:6)); summary(FS_MCOD6)
# Se selecciona el modelo que minimice el AIC
cbind(AIC(FS_MCOD1), AIC(FS_MCOD2), AIC(FS_MCOD3), AIC(FS_MCOD4), AIC(FS_MCOD5), AIC(FS_MCOD6))
# Se elige el modelo con 6 rezagos y 6 adelantos, en tanto tuvo el menor AIC
summary(FS_MCOD6)
# También es posible encontrar los resultados de la regresión utilizando
# el comando tidy() del paquete broom
tidy_FS_MCOD6 = tidy(FS_MCOD6)
# Parámetro/vector de cointegración calculado por MCO:
coint_param_MCOD = tidy_FS_MCOD6$estimate[2]; coint_param_MCOD
# Parámetro/vector de cointegración que se obtuvó empleando MCO
parametro_cointegración_MCO = coint_param_MCO
VEC_EQ1 <- dynlm(d(TB10YS) ~  L(TB10YS - parametro_cointegración_MCO * TB3MS,1) + L(d(TB3MS), 0:3) + L(d(TB10YS), 1:3));summary(VEC_EQ1) #El parámetro de velocidad de ajuste alpha tiene el signo esperado
VEC_EQ2 <- dynlm(d(TB3MS) ~  L(TB10YS - parametro_cointegración_MCO * TB3MS,1)+ L(d(TB3MS), 1:3) + L(d(TB10YS), 0:3));summary(VEC_EQ2) #El parámetro de velocidad de ajuste alpha tiene el signo esperado
# Parámetro/vector de cointegración que se obtuvó empleando MCO
parametro_cointegración_MCOD = coint_param_MCOD
VEC_EQ3 <- dynlm(d(TB10YS) ~  L(TB10YS - parametro_cointegración_MCOD * TB3MS, 1) + L(d(TB3MS), 0:3) + L(d(TB10YS), 1:3));summary(VEC_EQ3) #El parámetro de velocidad de ajuste alpha tiene el signo esperado
VEC_EQ4 <- dynlm(d(TB3MS) ~  L(TB10YS - parametro_cointegración_MCOD * TB3MS, 1)+ L(d(TB3MS), 1:3) + L(d(TB10YS), 0:3));summary(VEC_EQ4) #El parámetro de velocidad de ajuste alpha tiene el signo esperado
#Analizamos que los residuales sean estacionarios.
adf_VEC_EQ3 = ur.df(residuals(VEC_EQ3), lag=6, type = "none"); plot(adf_VEC_EQ3)
summary(adf_VEC_EQ3) # Residuales estacionarios.
# Ecuación VEC_EQ3
adf_VEC_EQ3 = ur.df(residuals(VEC_EQ3), lag=1, type = "none"); plot(adf_VEC_EQ3)
summary(adf_VEC_EQ3) # Residuales estacionarios.
# Ecuación VEC_EQ4
adf_VEC_EQ4 = ur.df(residuals(VEC_EQ4), lag=1, type = "none"); plot(adf_VEC_EQ4)
summary(adf_VEC_EQ4) #Residuales estacionarios.
# Test para probar que los residuales son ruido blanco
length(residuales_VEC_EQ3)
# Cálculo de los residuales del modelo:
residuales_VEC_EQ3 = residuals(VEC_EQ3)
residuales_VEC_EQ4 = residuals(VEC_EQ4)
# Ecuación VEC_EQ3
adf_VEC_EQ3 = ur.df(residuales_VEC_EQ3, lag=1, type = "none"); plot(adf_VEC_EQ3)
summary(adf_VEC_EQ3) # Residuales estacionarios.
# Ecuación VEC_EQ4
adf_VEC_EQ4 = ur.df(residuales_VEC_EQ4, lag=1, type = "none"); plot(adf_VEC_EQ4)
summary(adf_VEC_EQ4) #Residuales estacionarios.
# Test para probar que los residuales son ruido blanco
length(residuales_VEC_EQ3)
# Test para probar que los residuales son ruido blanco
length(residuales_VEC_EQ3)/4
# Test Box-Pierce para autocorrelación en los residuales
Box.test(residuales_VEC_EQ3,lag=60, type = c("Box-Pierce")) #No rechazo H0, se cumple el supuesto.
Box.test(residuales_VEC_EQ3,type='Box-Pierce',lag=20) #No rechazo H0, se cumple el supuesto.
Box.test(residuales_VEC_EQ3,type='Box-Pierce',lag=30) #No rechazo H0,  se cumple el supuesto.
Box.test(residuales_VEC_EQ4,lag=60, type = c("Ljung-Box")) #NO rechazo H0, se cumple el supuesto.
Box.test(residuales_VEC_EQ4,type='Ljung-Box',lag=20) #NO rechazo H0, se cumple el supuesto.
Box.test(residuales_VEC_EQ4,type='Ljung-Box',lag=30) #NO rechazo H0,  se cumple el supuesto.
